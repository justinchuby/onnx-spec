attributes:
- default_value: 1.673200011253357
  description: Coefficient of SELU default to 1.6732.
  name: alpha
  required: false
  type: AttrType.FLOAT
- default_value: null
  description: legacy optimization attribute.
  name: consumed_inputs
  required: false
  type: AttrType.INTS
- default_value: 1.0506999492645264
  description: Coefficient of SELU default to 1.0507.
  name: gamma
  required: false
  type: AttrType.FLOAT
deprecated: false
doc: '

  Selu takes one input data (Tensor<T>) and produces one output data

  (Tensor<T>) where the scaled exponential linear unit function,

  `y = gamma * (alpha * e^x - alpha) for x <= 0`, `y = gamma * x for x > 0`,

  is applied to the tensor elementwise.

  '
domain: ''
inputs:
- description: Input tensor
  min_arity: 1
  name: X
  tags: []
  type_str: T
max_input: 1
max_output: 1
min_input: 1
min_output: 1
name: Selu
outputs:
- description: Output tensor
  min_arity: 1
  name: Y
  tags: []
  type_str: T
since_version: 1
support_level: SupportType.COMMON
type_constraints:
- allowed_type_strs:
  - tensor(float16)
  - tensor(float)
  - tensor(double)
  description: Constrain input and output types to float tensors.
  type_param_str: T
