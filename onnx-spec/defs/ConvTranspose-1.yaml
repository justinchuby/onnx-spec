domain: ''
name: ConvTranspose
since_version: 1
min_input: 2
max_input: 3
min_output: 1
max_output: 1
doc: "\nThe convolution transpose operator consumes an input tensor and a filter,\n\
  and computes the output.\n\nIf the pads parameter is provided the shape of the output\
  \ is calculated via the following equation:\n\n  output_shape[i] = stride[i] * (input_size[i]\
  \ - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i] + 1) - pads[start_i]\
  \ - pads[end_i]\n\noutput_shape can also be explicitly specified in which case pads\
  \ values are auto generated using these equations:\n\n  total_padding[i] = stride[i]\
  \ * (input_size[i] - 1) + output_padding[i] + ((kernel_shape[i] - 1) * dilations[i]\
  \ + 1) - output_shape[i]\n  If (auto_pads != SAME_UPPER): pads[start_i] = total_padding[i]/2;\
  \ pads[end_i] = total_padding[i] - (total_padding[i]/2)\n  Else: pads[start_i] =\
  \ total_padding[i] - (total_padding[i]/2); pads[end_i] = (total_padding[i]/2).\n\
  \n"
attributes:
- name: auto_pad
  description: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where
    default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER
    mean pad the input so that the output spatial size match the input.In case of
    odd number add the extra padding at the end for SAME_UPPER and at the beginning
    for SAME_LOWER. VALID mean no padding.
  type: AttrType.STRING
  required: false
  default_value: NOTSET
- name: dilations
  description: dilation value along each spatial axis of the filter.
  type: AttrType.INTS
  required: false
  default_value: null
- name: group
  description: number of groups input channels and output channels are divided into.
  type: AttrType.INT
  required: false
  default_value: 1
- name: kernel_shape
  description: The shape of the convolution kernel. If not present, should be inferred
    from input W.
  type: AttrType.INTS
  required: false
  default_value: null
- name: output_padding
  description: The zero-padding added to one side of the output. This is also called
    adjs/adjustment in some frameworks.
  type: AttrType.INTS
  required: false
  default_value: null
- name: output_shape
  description: The shape of the output can be explicitly set which will cause pads
    values to be auto generated. If output_shape is specified pads values are ignored.
    See doc for details for equations to generate pads
  type: AttrType.INTS
  required: false
  default_value: null
- name: pads
  description: Padding for the beginning and ending along each spatial axis, it can
    take any value greater than or equal to 0. The value represent the number of pixels
    added to the beginning and end part of the corresponding axis. `pads` format should
    be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number
    of pixels added at the beginning of axis `i` and xi_end, the number of pixels
    added at the end of axis `i`. This attribute cannot be used simultaneously with
    auto_pad attribute. If not present, the padding defaults to 0 along start and
    end of each spatial axis.
  type: AttrType.INTS
  required: false
  default_value: null
- name: strides
  description: Stride along each spatial axis.
  type: AttrType.INTS
  required: false
  default_value: null
inputs:
- name: X
  type_str: T
  description: Input data tensor from previous layer; has size (N x C x H x W), where
    N is the batch size, C is the number of channels, and H and W are the height and
    width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x
    D2 ... x Dn)
  min_arity: 1
  tags: []
- name: W
  type_str: T
  description: The weight tensor that will be used in the convolutions; has size (C
    x M/group x kH x kW), where C is the number of channels, and kH and kW are the
    height and width of the kernel, and M is the number of feature maps. For more
    than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn),
    where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels
    in the output should be equal to W.shape[1] * group (assuming zero based indices
    of the shape array)
  min_arity: 1
  tags: []
- name: B
  type_str: T
  description: Optional 1D bias to be added to the convolution, has size of M.
  min_arity: 1
  tags:
  - optional
outputs:
- name: Y
  type_str: T
  description: Output data tensor that contains the result of the convolution. The
    output dimensions are functions of the kernel size, stride size, pad lengths and
    group count. The number of channels in the output should be equal to W.shape[1]
    * group (assuming zero based indices of the shape array)
  min_arity: 1
  tags: []
type_constraints:
- type_param_str: T
  description: Constrain input and output types to float tensors.
  allowed_type_strs:
  - tensor(float16)
  - tensor(float)
  - tensor(double)
support_level: COMMON
deprecated: false
