domain: ''
name: QuantizeLinear
since_version: 21
min_input: 2
max_input: 3
min_output: 1
max_output: 1
doc: |-
  The linear quantization operator. It consumes a high precision tensor, a scale, and a zero point to compute the low precision / quantized tensor.
  The scale factor and zero point must have same shape, and can be either a scalar for per-tensor / per layer quantization, or a 1-D tensor for per-axis quantization.
  The quantization formula is `y = saturate ((x / y_scale) + y_zero_point)`.
  For saturation, it saturates according to:
  uint8: [0, 255], int8: [-128, 127], uint16: [0, 65535], int16: [-32768, 32767], uint4: [0, 15], int4: [-8, 7]
  For (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details.
  'y_zero_point' and 'y' must have same type.
  'y_zero_point' is usually not used for quantization to float8e4m3fn, float8e4m3fnuz, float8e5m2, float8e5m2fnuz,
  but the quantization formula remains the same for consistency and
  the type of the attribute 'y_zero_point' still determines the quantization type.
attributes:
  - name: axis
    description: (Optional) The axis of the quantization dimension of the input tensor.
      Ignored for per-tensor quantization. Negative value means counting dimensions
      from the back. Accepted range is [-r, r-1] where r = rank(input).
    type: INT
    required: false
    default_value: 1
  - name: saturate
    description: The parameter defines how the conversion behaves if an input value
      is out of range of the destination type. It only applies for float 8 quantization
      (float8e4m3fn, float8e4m3fnuz, float8e5m2, float8e5m2fnuz). It is true by default.
      All cases are fully described in two tables inserted in the operator description.
    type: INT
    required: false
    default_value: 1
inputs:
  - name: x
    type_str: T1
    description: N-D full precision Input tensor to be quantized.
    min_arity: 1
    tags: []
  - name: y_scale
    type_str: T1
    description: Scale for doing quantization to get 'y'. It can be a scalar, which
      means per-tensor/layer quantization, or a 1-D Tensor for per-axis quantization.
    min_arity: 1
    tags: []
  - name: y_zero_point
    type_str: T2
    description: Zero point for doing quantization to get 'y'. Shape must match y_scale.
      Default is uint8 with zero point of 0 if it's not specified.
    min_arity: 1
    tags:
      - optional
outputs:
  - name: y
    type_str: T2
    description: N-D quantized output tensor. It has same shape as input 'x'.
    min_arity: 1
    tags: []
type_constraints:
  - type_param_str: T1
    description: The type of the input 'x'.
    allowed_type_strs:
      - tensor(float)
      - tensor(float16)
      - tensor(bfloat16)
      - tensor(int32)
  - type_param_str: T2
    description: The type of the input 'y_zero_point' and the output 'y'.
    allowed_type_strs:
      - tensor(int8)
      - tensor(uint8)
      - tensor(int16)
      - tensor(uint16)
      - tensor(float8e4m3fn)
      - tensor(float8e4m3fnuz)
      - tensor(float8e5m2)
      - tensor(float8e5m2fnuz)
      - tensor(uint4)
      - tensor(int4)
support_level: COMMON
deprecated: false
