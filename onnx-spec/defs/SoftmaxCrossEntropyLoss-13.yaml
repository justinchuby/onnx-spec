domain: ''
name: SoftmaxCrossEntropyLoss
since_version: 13
min_input: 2
max_input: 3
min_output: 1
max_output: 2
doc: "Loss function that measures the softmax cross entropy\nbetween 'scores' and\
  \ 'labels'.\nThis operator first computes a loss tensor whose shape is identical\
  \ to the labels input.\nIf the input is 2-D with shape (N, C), the loss tensor may\
  \ be a N-element vector L = (l_1, l_2, ..., l_N).\nIf the input is N-D tensor with\
  \ shape (N, C, D1, D2, ..., Dk),\nthe loss tensor L may have (N, D1, D2, ..., Dk)\
  \ as its shape and L[i,][j_1][j_2]...[j_k] denotes a scalar element in L.\nAfter\
  \ L is available, this operator can optionally do a reduction operator.\n\n* shape(scores):\
  \ (N, C) where C is the number of classes, or (N, C, D1, D2,..., Dk),\n  with K\
  \ >= 1 in case of K-dimensional loss.\n* shape(labels): (N) where each value is\
  \ 0 <= labels[i] <= C-1, or (N, D1, D2,..., Dk),\n  with K >= 1 in case of K-dimensional\
  \ loss.\n\nThe loss for one sample, l_i, can calculated as follows:\n```\nl[i][d1][d2]...[dk]\
  \ = -y[i][c][d1][d2]..[dk], where i is the index of classes.\n```\nor\n```\nl[i][d1][d2]...[dk]\
  \ = -y[i][c][d1][d2]..[dk] * weights[c], if 'weights' is provided.\n```\n\nloss\
  \ is zero for the case when label-value equals ignore_index.\n```\nl[i][d1][d2]...[dk]\
  \  = 0, when labels[n][d1][d2]...[dk] = ignore_index\n```\n\nwhere:\n```\np = Softmax(scores)\n\
  y = Log(p)\nc = labels[i][d1][d2]...[dk]\n```\n\nFinally, L is optionally reduced:\n\
  \n* If reduction = 'none', the output is L with shape (N, D1, D2, ..., Dk).\n* If\
  \ reduction = 'sum', the output is scalar: Sum(L).\n* If reduction = 'mean', the\
  \ output is scalar: ReduceMean(L), or if weight is provided: `ReduceSum(L) / ReduceSum(W)`,\n\
  \  where tensor W is of shape `(N, D1, D2, ..., Dk)` and `W[n][d1][d2]...[dk] =\
  \ weights[labels[i][d1][d2]...[dk]]`.\n"
attributes:
- name: ignore_index
  description: Specifies a target value that is ignored and does not contribute to
    the input gradient. It's an optional value.
  type: AttrType.INT
  required: false
  default_value: null
- name: reduction
  description: 'Type of reduction to apply to loss: none, sum, mean(default). ''none'':
    no reduction will be applied, ''sum'': the output will be summed. ''mean'': the
    sum of the output will be divided by the number of elements in the output.'
  type: AttrType.STRING
  required: false
  default_value: mean
inputs:
- name: scores
  type_str: T
  description: The predicted outputs with shape [batch_size, class_size], or [batch_size,
    class_size, D1, D2 , ..., Dk], where K is the number of dimensions.
  min_arity: 1
  tags:
  - differentiable
- name: labels
  type_str: Tind
  description: The ground truth output tensor, with shape [batch_size], or [batch_size,
    D1, D2, ..., Dk], where K is the number of dimensions. Labels element value shall
    be in range of [0, C). If ignore_index is specified, it may have a value outside
    [0, C) and the label values should either be in the range [0, C) or have the value
    ignore_index.
  min_arity: 1
  tags:
  - non-differentiable
- name: weights
  type_str: T
  description: A manual rescaling weight given to each class. If given, it has to
    be a 1D Tensor assigning weight to each of the classes. Otherwise, it is treated
    as if having all ones.
  min_arity: 1
  tags:
  - optional
  - non-differentiable
outputs:
- name: output
  type_str: T
  description: Weighted loss float Tensor. If reduction is 'none', this has the shape
    of [batch_size], or [batch_size, D1, D2, ..., Dk] in case of K-dimensional loss.
    Otherwise, it is a scalar.
  min_arity: 1
  tags:
  - differentiable
- name: log_prob
  type_str: T
  description: Log probability tensor. If the output of softmax is prob, its value
    is log(prob).
  min_arity: 1
  tags:
  - optional
  - differentiable
type_constraints:
- type_param_str: T
  description: Constrain input and output types to float tensors.
  allowed_type_strs:
  - tensor(float16)
  - tensor(float)
  - tensor(double)
  - tensor(bfloat16)
- type_param_str: Tind
  description: Constrain target to integer types
  allowed_type_strs:
  - tensor(int32)
  - tensor(int64)
support_level: COMMON
deprecated: false
