attributes: []
deprecated: false
doc: '

  HardSwish takes one input data (Tensor<T>) and produces one output data (Tensor<T>)
  where

  the HardSwish function, y = x * max(0, min(1, alpha * x + beta)) = x * HardSigmoid<alpha,
  beta>(x),

  where alpha = 1/6 and beta = 0.5, is applied to the tensor elementwise.

  '
domain: ''
inputs:
- description: Input tensor
  min_arity: 1
  name: X
  tags:
  - differentiable
  type_str: T
max_input: 1
max_output: 1
min_input: 1
min_output: 1
name: HardSwish
outputs:
- description: Output tensor
  min_arity: 1
  name: Y
  tags:
  - differentiable
  type_str: T
since_version: 14
support_level: SupportType.COMMON
type_constraints:
- allowed_type_strs:
  - tensor(float16)
  - tensor(float)
  - tensor(double)
  description: Constrain input and output types to float tensors.
  type_param_str: T
