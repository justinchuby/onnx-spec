domain: ''
name: DequantizeLinear
since_version: 24
min_input: 2
max_input: 3
min_output: 1
max_output: 1
doc: |-
  The linear dequantization operator. It consumes a quantized tensor, a scale, and a zero point to compute the
  full-precision tensor. The dequantization formula is `y = (x - x_zero_point) * x_scale`. `x_scale` and `x_zero_point`
  must have the same shape, determining the quantization's granularity: a scalar for per-tensor/per-layer quantization,
  a 1-D tensor for per-axis quantization, or have a rank identical to the input for blocked quantization.
  See QuantizeLinear for details on quantization granularity.

  `x_zero_point` and `x` must have the same type. `x` and `y` must have the same shape. In the case of dequantizing
  `int32`, there's no zero point (zero point is supposed to be 0).
  `zero-point` is usually not used in the case of float8 and 4-bit types quantization, but the dequantization formula remains the same
  for consistency. The output type is determined by the attribute `output_dtype`. If `output_dtype` is not supplied then the output type
  is the same as `x_scale`. The output type also determines the precision of the multiplication operation.
attributes:
  - name: output_dtype
    description: >-
      (Optional) The output data type. If not supplied, the output data type is inferred
      from `x_scale` data type (`T2`)
    type: INT
    required: false
    default_value: 0
  - name: block_size
    description: >-
      (Optional) The size of the quantization block (number of times every scale is
      replicated). Used only for blocked quantization. The block size is a positive
      integer. Given `x` shape `(D0, ..., Di, ..., Dn)`, `y_scale` shape `(S0, ...
      Si, ...Sn)` and `axis=i`, the accepted range is `[ceil(Di/Si), ceil(Di/(Si-1))-1]`
    type: INT
    required: false
    default_value: 0
  - name: axis
    description: >-
      (Optional) The axis of the dequantizing dimension of the input tensor. Used
      for per-axis and blocked quantization. Negative value means counting dimensions
      from the back. Accepted range is `[-r, r-1]` where `r = rank(input)`.
    type: INT
    required: false
    default_value: 1
inputs:
  - name: x
    type_str: T1
    description: N-D quantized input tensor to be de-quantized.
    min_arity: 1
    tags: []
  - name: x_scale
    type_str: T2
    description: Scale for input `x`. For per-tensor/layer dequantization the 
      scale is a scalar, for per per-axis dequantization it is a 1-D Tensor and 
      for blocked dequantization it has the same shape as the input, except for 
      one dimension in which blocking is performed.
    min_arity: 1
    tags: []
  - name: x_zero_point
    type_str: T1
    description: Zero point for input `x`. Shape must match x_scale. It's 
      optional. Zero point is 0 when it's not specified.
    min_arity: 1
    tags:
      - optional
outputs:
  - name: y
    type_str: T3
    description: N-D full precision output tensor. It has the same shape as 
      input `x`. The data type is specified by the `output_dtype` attribute or, 
      in its absence, the type of `x_scale`.
    min_arity: 1
    tags: []
type_constraints:
  - type_param_str: T1
    description: The type of the inputs 'x_zero_point' and 'x'.
    allowed_type_strs:
      - tensor(int8)
      - tensor(uint8)
      - tensor(int16)
      - tensor(uint16)
      - tensor(int32)
      - tensor(float8e4m3fn)
      - tensor(float8e4m3fnuz)
      - tensor(float8e5m2)
      - tensor(float8e5m2fnuz)
      - tensor(uint4)
      - tensor(int4)
      - tensor(float4e2m1)
  - type_param_str: T2
    description: The type of the input 'x_scale'.
    allowed_type_strs:
      - tensor(float)
      - tensor(float16)
      - tensor(bfloat16)
      - tensor(float8e8m0)
  - type_param_str: T3
    description: The type of the output 'y'.
    allowed_type_strs:
      - tensor(float)
      - tensor(float16)
      - tensor(bfloat16)
support_level: COMMON
deprecated: false
