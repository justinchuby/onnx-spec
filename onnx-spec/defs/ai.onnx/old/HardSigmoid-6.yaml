domain: ''
name: HardSigmoid
since_version: 6
min_input: 1
max_input: 1
min_output: 1
max_output: 1
doc: |-
  HardSigmoid takes one input data (Tensor<T>) and produces one output data
  (Tensor<T>) where the HardSigmoid function, y = max(0, min(1, alpha * x + beta)),
  is applied to the tensor elementwise.
attributes:
  - name: alpha
    description: >-
      Value of alpha.
    type: FLOAT
    required: false
    default_value: 0.20000000298023224
  - name: beta
    description: >-
      Value of beta.
    type: FLOAT
    required: false
    default_value: 0.5
inputs:
  - name: X
    type_str: T
    description: Input tensor
    min_arity: 1
    tags:
      - differentiable
outputs:
  - name: Y
    type_str: T
    description: Output tensor
    min_arity: 1
    tags:
      - differentiable
type_constraints:
  - type_param_str: T
    description: Constrain input and output types to float tensors.
    allowed_type_strs:
      - tensor(float16)
      - tensor(float)
      - tensor(double)
function: |-
  <
    domain: "",
    opset_import: ["" : 18]
  >
  HardSigmoid <beta,alpha>(X) => (Y)
  {
     Alpha = Constant <value_float: float = @alpha> ()
     AlphaCast = CastLike (Alpha, X)
     Beta = Constant <value_float: float = @beta> ()
     BetaCast = CastLike (Beta, X)
     Zero = Constant <value: tensor = float {0}> ()
     ZeroCast = CastLike (Zero, X)
     One = Constant <value: tensor = float {1}> ()
     OneCast = CastLike (One, X)
     AlphaMulX = Mul (X, AlphaCast)
     AlphaMulXAddBeta = Add (AlphaMulX, BetaCast)
     MinOneOrAlphaMulXAddBeta = Min (AlphaMulXAddBeta, OneCast)
     Y = Max (MinOneOrAlphaMulXAddBeta, ZeroCast)
  }
support_level: COMMON
deprecated: false
