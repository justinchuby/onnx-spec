domain: ''
name: QuantizeLinear
since_version: 10
min_input: 2
max_input: 3
min_output: 1
max_output: 1
doc: |-
  The linear per-tensor/layer quantization operator. It consumes a high precision tensor, a scale, a zero point to compute the low precision / quantized tensor.
  The quantization formula is y = saturate ((x / y_scale) + y_zero_point). For saturation, it saturates to [0, 255] if it's uint8, or [-128, 127] if it's int8.
  For (x / y_scale), it's rounding to the nearest even. Refer to https://en.wikipedia.org/wiki/Rounding for details. 'y_zero_point' and 'y' must have same type.
attributes: []
inputs:
  - name: x
    type_str: T1
    description: N-D full precision Input tensor to be quantized.
    min_arity: 1
    tags: []
  - name: y_scale
    type_str: tensor(float)
    description: Scale for doing quantization to get 'y'. It's a scalar, which means
      a per-tensor/layer quantization.
    min_arity: 1
    tags: []
  - name: y_zero_point
    type_str: T2
    description: Zero point for doing quantization to get 'y'. It's a scalar, which
      means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's
      not specified.
    min_arity: 1
    tags:
      - optional
outputs:
  - name: y
    type_str: T2
    description: N-D quantized output tensor. It has same shape as input 'x'.
    min_arity: 1
    tags: []
type_constraints:
  - type_param_str: T1
    description: Constrain 'x' to float or int32 tensor.
    allowed_type_strs:
      - tensor(float)
      - tensor(int32)
  - type_param_str: T2
    description: Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
    allowed_type_strs:
      - tensor(int8)
      - tensor(uint8)
support_level: COMMON
deprecated: false
