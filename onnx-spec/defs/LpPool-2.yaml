attributes:
- default_value: NOTSET
  description: auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where
    default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER
    mean pad the input so that the output spatial size match the input.In case of
    odd number add the extra padding at the end for SAME_UPPER and at the beginning
    for SAME_LOWER. VALID mean no padding.
  name: auto_pad
  required: false
  type: AttrType.STRING
- default_value: null
  description: The size of the kernel along each axis.
  name: kernel_shape
  required: true
  type: AttrType.INTS
- default_value: 2
  description: p value of the Lp norm used to pool over the input data.
  name: p
  required: false
  type: AttrType.INT
- default_value: null
  description: Padding for the beginning and ending along each spatial axis, it can
    take any value greater than or equal to 0. The value represent the number of pixels
    added to the beginning and end part of the corresponding axis. `pads` format should
    be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number
    of pixels added at the beginning of axis `i` and xi_end, the number of pixels
    added at the end of axis `i`. This attribute cannot be used simultaneously with
    auto_pad attribute. If not present, the padding defaults to 0 along start and
    end of each spatial axis.
  name: pads
  required: false
  type: AttrType.INTS
- default_value: null
  description: Stride along each spatial axis.
  name: strides
  required: false
  type: AttrType.INTS
deprecated: false
doc: "\n LpPool consumes an input tensor X and applies Lp pooling across\n the tensor\
  \ according to kernel sizes, stride sizes, and pad lengths.\n Lp pooling consisting\
  \ of computing the Lp norm on all values of a subset\n of the input tensor according\
  \ to the kernel size and downsampling the\n data into the output tensor Y for further\
  \ processing."
domain: ''
inputs:
- description: Input data tensor from the previous operator; dimensions for image
    case are (N x C x H x W), where N is the batch size, C is the number of channels,
    and H and W are the height and the width of the data. For non image case, the
    dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
  min_arity: 1
  name: X
  tags: []
  type_str: T
max_input: 1
max_output: 1
min_input: 1
min_output: 1
name: LpPool
outputs:
- description: Output data tensor from Lp pooling across the input tensor. Dimensions
    will vary based on various kernel, stride, and pad sizes.
  min_arity: 1
  name: Y
  tags: []
  type_str: T
since_version: 2
support_level: SupportType.COMMON
type_constraints:
- allowed_type_strs:
  - tensor(float16)
  - tensor(float)
  - tensor(double)
  description: Constrain input and output types to float tensors.
  type_param_str: T
