attributes:
- default_value: 1.6732631921768188
  description: Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32
    approximation of 1.6732632423543772848170429916717).
  name: alpha
  required: false
  type: AttrType.FLOAT
- default_value: 1.0507010221481323
  description: Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32
    approximation of 1.0507009873554804934193349852946).
  name: gamma
  required: false
  type: AttrType.FLOAT
deprecated: false
doc: '

  Selu takes one input data (Tensor<T>) and produces one output data

  (Tensor<T>) where the scaled exponential linear unit function,

  `y = gamma * (alpha * e^x - alpha) for x <= 0`, `y = gamma * x for x > 0`,

  is applied to the tensor elementwise.

  '
domain: ''
inputs:
- description: Input tensor
  min_arity: 1
  name: X
  tags:
  - differentiable
  type_str: T
max_input: 1
max_output: 1
min_input: 1
min_output: 1
name: Selu
outputs:
- description: Output tensor
  min_arity: 1
  name: Y
  tags:
  - differentiable
  type_str: T
since_version: 6
support_level: SupportType.COMMON
type_constraints:
- allowed_type_strs:
  - tensor(float16)
  - tensor(float)
  - tensor(double)
  description: Constrain input and output types to float tensors.
  type_param_str: T
