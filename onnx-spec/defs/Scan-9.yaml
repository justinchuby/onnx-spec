attributes:
- default_value: null
  description: 'The graph run each iteration. It has N+M inputs: (loop state variables...,
    scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...).
    Each scan_output is created by concatenating the value of the specified scan_output_elt
    value at the end of each iteration of the loop. It is an error if the dimensions
    of these values change across loop iterations.'
  name: body
  required: true
  type: AttrType.GRAPH
- default_value: null
  description: 'An attribute specifying the number of scan_inputs M. '
  name: num_scan_inputs
  required: true
  type: AttrType.INT
- default_value: null
  description: An optional list of M flags. The i-th element of the list specifies
    the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted,
    0 will be used as the scan axis for every scan_input.
  name: scan_input_axes
  required: false
  type: AttrType.INTS
- default_value: null
  description: 'An optional list of M flags. The i-th element of the list specifies
    the direction to be scanned for the i-th scan_input tensor: 0 indicates forward
    direction and 1 indicates reverse direction. If omitted, all scan_input tensors
    will be scanned in the forward direction.'
  name: scan_input_directions
  required: false
  type: AttrType.INTS
- default_value: null
  description: An optional list of K flags. The i-th element of the list specifies
    the axis for the i-th scan_output. The scan outputs are accumulated along the
    specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
  name: scan_output_axes
  required: false
  type: AttrType.INTS
- default_value: null
  description: 'An optional list of K flags, one for each scan_output. The i-th element
    of the list specifies whether the i-th scan_output should be constructed by appending
    or prepending a new value in each iteration: 0 indicates appending and 1 indicates
    prepending. If omitted, all scan_output tensors will be produced by appending
    a value in each iteration.'
  name: scan_output_directions
  required: false
  type: AttrType.INTS
deprecated: false
doc: "\nScan can be used to iterate over one or more scan_input tensors,\nconstructing\
  \ zero or more scan_output tensors. It combines ideas from general recurrences,\n\
  functional programming constructs such as scan, fold, map, and zip, and is intended\
  \ to enable\ngeneralizations of RNN-like constructs for sequence-to-sequence processing.\n\
  Other tensors (referred to as state_variables here) can be used to carry a state\n\
  when iterating from one element to another (similar to hidden-state in RNNs, also\
  \ referred\nto as loop-carried dependences in the context of loops).\nMany common\
  \ usages involve a single scan_input tensor (where functionality\nsimilar to scan,\
  \ fold and map can be obtained). When more than one scan_input is used,\na behavior\
  \ similar to zip is obtained.\n\nThe attribute body must be a graph, specifying\
  \ the computation to be performed in\nevery iteration. It takes as input the current\
  \ values of the state_variables and\nthe current iterated element of the scan_inputs.\
  \ It must return the (updated) values\nof the state_variables and zero or more scan_output_element\
  \ tensors. The values of the\nscan_output_element tensors are concatenated over\
  \ all the iterations to produce the\nscan_output values of the scan construct (similar\
  \ to the concatenated intermediate\nhidden-state values of RNN-like constructs).\
  \ All the output tensors (state_variables as\nwell as scan_output_element tensors)\
  \ are required to have the same shape in each iteration\nof the loop (a restriction\
  \ imposed to enable efficient memory allocation).\n\nNote that the iterated element\
  \ passed to the body subgraph does not have a sequence\naxis. It will have a rank\
  \ one less than the rank of the corresponding scan_input.\n\nThe scan operation\
  \ returns the final values of the state_variables as well as the\nscan_outputs.\n\
  \nThe optional attribute scan_input_directions specifies the direction (forward\
  \ or backward)\nfor each scan input. If this attribute is omitted, all sequences\
  \ are scanned in the forward\ndirection. A bidirectional scan may be performed by\
  \ specifying the same tensor input twice\nin the scan_inputs, once with a forward\
  \ direction, and once with a backward direction.\n\nThe scan_output of the operation\
  \ is produced by concatenating the scan_output_element\nvalues produced by the body\
  \ in each iteration.  The optional attribute scan_output_directions\nspecifies the\
  \ direction in which scan_output is constructed (by appending or prepending the\n\
  scan_output_element to scan_output in each iteration) for each scan_output. If this\
  \ attribute\nis omitted, the scan_output_element is appended to the scan_output\
  \ in each iteration.\n\nThe optional attribute scan_input_axes specifies the axis\
  \ to be scanned for each scan_input.\nIf omitted, every scan_input will be scanned\
  \ in axis 0. For example, if axis 0 is the\nbatch axis and axis 1 is the time axis\
  \ (to be scanned), specify an axis value of 1.\nNote that scanning a non-zero axis\
  \ may be less efficient than scanning axis zero.\n\nThe optional attribute scan_output_axes\
  \ specifies the axis along which the scan_outputs\nare accumulated for each scan_output.\
  \ For example, if axis 1 is the time axis (to be\nscanned) for both inputs and outputs,\
  \ specify a scan_input axis and scan_output axis\nvalue of 1.\n\nNote that because\
  \ of the ONNX restriction that only the last parameter of an operator can\nbe variadic,\
  \ the initial-states and scan-inputs are listed together as one input parameter.\n\
  Similarly, the final-states and scan-outputs are listed together as one output parameter.\n\
  The attribute num_scan_inputs indicates the number M of scan-inputs.\n\nThe behavior\
  \ of\n\n    Scan <\n        num_scan_inputs = m,\n        body = loop-body,\n  \
  \      scan_input_axes = [axis_1, ..., axis_m]\n    > (init_1, ..., init_n, scan_1,\
  \ ..., scan_m)\n\nis equivalent to the following pseudo-code:\n\n    // scan_i.shape[axis_i]\
  \ denotes the (max) sequence-length of scan_i\n    // scan_i.shape[axis_i] is required\
  \ to be equal to scan_j.shape[axis_j] for all i,j.\n    sequence_length = scan_1.shape[axis_1];\n\
  \n    // initialize state-variables\n    st_1 = init_1; ... st_n = init_n;\n   \
  \ // initialize scan-output variables: [] denotes an empty tensor\n    scan_out_1\
  \ = []; ...; scan_out_k = [];\n    // identify number of iterations:\n\n    // execute\
  \ loop\n    for (int t = 0; t < sequence_length; ++t) {\n        // generate the\
  \ scan-input elements: the notation T<axis=k>[t] indicates the sub-tensor\n    \
  \    // of rank one less than T obtained by indexing T at position t along axis\
  \ k.\n        si_1 = scan_1<axis=axis_1>[t];\n        ... ;\n        si_m = scan_m<axis=axis_m>[t];\n\
  \        // execute loop-body\n        st_1, ..., st_n, so_1, ..., so_k = loop-body(st_1,\
  \ ..., st_n, si_1, ..., si_m)\n        // accumulate the scan-output elements\n\
  \        scan_out_1 = Concat<axis=0>(scan_out_1, so_1); ... ; scan_out_k = Concat<axis=0>(scan_out_k,\
  \ so_k);\n    }\n\n    return st_1, ..., st_n, scan_out_1, ..., scan_out_k;\n\n\
  *Sample usage: Encoding RNN using a Scan*\n\nThe following example shows how a simple\
  \ RNN over an input tensor %X, with weight tensor %Wi,\nrecurrence weight tensor\
  \ %Ri, bias tensors %Wbi and %Rbi, and initial hidden-state %H_0 can\nbe encoded\
  \ as a ScanLoop. Note that the loop-body is a nested graph, and it directly computes\n\
  %Wi, %Ri, %Wbi, and %Rbi (typically constants or initializers in the body graph).\
  \ If these\nvalues are computed in the outer graph, they need to be passed in as\
  \ extra state_variables.\n\n    graph rnn-encoding {\n      %H_0 = ...\n      %X\
  \ = ...\n      %Y_h, %Y = Scan[body = <graph rnn-cell-1>, num_scan_inputs=1](%H_0,\
  \ %X)\n      return %Y, %Y_h\n    }\n\n    graph rnn-cell-1 (\n      %H_tminus1[FLOAT,\
  \ tensor]\n      %X_t[FLOAT, tensor]\n    ) {\n      %Wi = ...\n      %Ri = ...\n\
  \      %Wbi = ...\n      %Rbi = ...\n      %t1 = X_t * (Wi^T)\n      %t2 = H_tminus1*(Ri^T)\n\
  \      %t3 = Add(%t1, %t2)\n      %t4 = Add(%t3, %Wbi)\n      %t5 = Add(%t4, %Rbi)\n\
  \      %Ht = Tanh(%t5)\n      %Accumulate = Identity(%Ht)\n      return %Ht, %Accumulate\n\
  \    }\n\n"
domain: ''
inputs:
- description: Initial values of the loop's N state variables followed by M scan_inputs
  min_arity: 1
  name: initial_state_and_scan_inputs
  tags:
  - variadic
  - heterogeneous
  type_str: V
max_input: 2147483647
max_output: 2147483647
min_input: 1
min_output: 1
name: Scan
outputs:
- description: Final values of the loop's N state variables followed by K scan_outputs
  min_arity: 1
  name: final_state_and_scan_outputs
  tags:
  - variadic
  - heterogeneous
  type_str: V
since_version: 9
support_level: SupportType.COMMON
type_constraints:
- allowed_type_strs:
  - tensor(uint8)
  - tensor(uint16)
  - tensor(uint32)
  - tensor(uint64)
  - tensor(int8)
  - tensor(int16)
  - tensor(int32)
  - tensor(int64)
  - tensor(float16)
  - tensor(float)
  - tensor(double)
  - tensor(string)
  - tensor(bool)
  - tensor(complex64)
  - tensor(complex128)
  description: All Tensor types
  type_param_str: V
